
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="A comprehensive study guide for AWS ML professionals preparing for the Google Cloud Professional Machine Learning">
      
      
      
      
        <link rel="prev" href="..">
      
      
        <link rel="next" href="../ds_concepts/">
      
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.20">
    
    
      
        <title>ML Concepts - GCP ML Engineer Certification Preparation Guide</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.e53b48f4.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CJetBrains+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"JetBrains Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../styles.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#machine-learning-concepts---quick-reference" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="GCP ML Engineer Certification Preparation Guide" class="md-header__button md-logo" aria-label="GCP ML Engineer Certification Preparation Guide" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            GCP ML Engineer Certification Preparation Guide
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ML Concepts
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-hidden="true"  type="radio" name="__palette" id="__palette_0">
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="GCP ML Engineer Certification Preparation Guide" class="md-nav__button md-logo" aria-label="GCP ML Engineer Certification Preparation Guide" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    GCP ML Engineer Certification Preparation Guide
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href=".." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Study Guide
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Study Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    ML Concepts
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    ML Concepts
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-core-ml-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      1. Core ML Concepts
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Core ML Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Unsupervised Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-ml-algorithm-types" class="md-nav__link">
    <span class="md-ellipsis">
      2. ML Algorithm Types
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. ML Algorithm Types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-trees" class="md-nav__link">
    <span class="md-ellipsis">
      Decision Trees
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forest" class="md-nav__link">
    <span class="md-ellipsis">
      Random Forest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-boosting-xgboost-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Boosting (XGBoost, LightGBM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machines-svm" class="md-nav__link">
    <span class="md-ellipsis">
      Support Vector Machines (SVM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-means-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      K-Means Clustering
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbors-knn" class="md-nav__link">
    <span class="md-ellipsis">
      K-Nearest Neighbors (KNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-networks-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks (Deep Learning)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes" class="md-nav__link">
    <span class="md-ellipsis">
      Naive Bayes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-cut-forest-rcf" class="md-nav__link">
    <span class="md-ellipsis">
      Random Cut Forest (RCF)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#principal-component-analysis-pca" class="md-nav__link">
    <span class="md-ellipsis">
      Principal Component Analysis (PCA)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-model-validation-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      3. Model Validation Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Model Validation Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#train-test-split" class="md-nav__link">
    <span class="md-ellipsis">
      Train-Test Split
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      Cross-Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-fold-cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      K-Fold Cross-Validation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-evaluation-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      4. Evaluation Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Evaluation Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#confusion-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Confusion Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy" class="md-nav__link">
    <span class="md-ellipsis">
      Accuracy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision" class="md-nav__link">
    <span class="md-ellipsis">
      Precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recall-sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      Recall (Sensitivity)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#f1-score" class="md-nav__link">
    <span class="md-ellipsis">
      F1 Score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc-curve-receiver-operating-characteristic" class="md-nav__link">
    <span class="md-ellipsis">
      ROC Curve (Receiver Operating Characteristic)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auc-area-under-the-roc-curve" class="md-nav__link">
    <span class="md-ellipsis">
      AUC (Area Under the ROC Curve)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auc-pr-area-under-the-precision-recall-curve" class="md-nav__link">
    <span class="md-ellipsis">
      AUC-PR (Area Under the Precision-Recall Curve)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      5. Loss Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Loss Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mean-squared-error-mse" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Squared Error (MSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-absolute-error-mae" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Error (MAE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#huber-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Huber Loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-cross-entropy-log-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Binary Cross-Entropy (Log Loss)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#categorical-cross-entropy" class="md-nav__link">
    <span class="md-ellipsis">
      Categorical Cross-Entropy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse-categorical-cross-entropy" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Categorical Cross-Entropy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hinge-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Hinge Loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focal-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Focal Loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kullback-leibler-kl-divergence" class="md-nav__link">
    <span class="md-ellipsis">
      Kullback-Leibler (KL) Divergence
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-optimization-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      6. Optimization Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Optimization Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sgd-stochastic-gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      SGD (Stochastic Gradient Descent)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#momentum" class="md-nav__link">
    <span class="md-ellipsis">
      Momentum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adam-adaptive-moment-estimation" class="md-nav__link">
    <span class="md-ellipsis">
      Adam (Adaptive Moment Estimation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rmsprop-root-mean-square-propagation" class="md-nav__link">
    <span class="md-ellipsis">
      RMSprop (Root Mean Square Propagation)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-training-hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      7. Training Hyperparameters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Training Hyperparameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mini-batch" class="md-nav__link">
    <span class="md-ellipsis">
      Mini-batch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-model-performance-issues" class="md-nav__link">
    <span class="md-ellipsis">
      8. Model Performance Issues
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Model Performance Issues">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bias-variance-tradeoff" class="md-nav__link">
    <span class="md-ellipsis">
      Bias-Variance Tradeoff
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overfitting" class="md-nav__link">
    <span class="md-ellipsis">
      Overfitting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#underfitting" class="md-nav__link">
    <span class="md-ellipsis">
      Underfitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-regularization-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      9. Regularization Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Regularization Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#l1-regularization-lasso" class="md-nav__link">
    <span class="md-ellipsis">
      L1 Regularization (Lasso)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l2-regularization-ridge" class="md-nav__link">
    <span class="md-ellipsis">
      L2 Regularization (Ridge)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#early-stopping" class="md-nav__link">
    <span class="md-ellipsis">
      Early Stopping
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-advanced-ml-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      10. Advanced ML Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Advanced ML Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collaborative-filtering" class="md-nav__link">
    <span class="md-ellipsis">
      Collaborative Filtering
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ds_concepts/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Science Concepts
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../gcp-aws-compare/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    GCP & AWS Comparison
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../technical/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Technical Aspects
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../patterns/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Architectural Patterns
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../kube_ml_flow/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    MLFlow vs Kubeflow
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="">
            
  
  
  <span class="md-ellipsis">
    Reference
    
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Reference
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../scenarios/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Common Scenarios
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../ds_techniques/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Science Techniques
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../data_split/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Data Splitting Strategies
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../labs/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Hands-On Labs
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../reference/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Quick Reference
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../glossary/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Glossary
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../LICENSE/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    License
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#overview" class="md-nav__link">
    <span class="md-ellipsis">
      Overview
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-core-ml-concepts" class="md-nav__link">
    <span class="md-ellipsis">
      1. Core ML Concepts
    </span>
  </a>
  
    <nav class="md-nav" aria-label="1. Core ML Concepts">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#supervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Supervised Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#unsupervised-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Unsupervised Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#reinforcement-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Reinforcement Learning
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-ml-algorithm-types" class="md-nav__link">
    <span class="md-ellipsis">
      2. ML Algorithm Types
    </span>
  </a>
  
    <nav class="md-nav" aria-label="2. ML Algorithm Types">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#linear-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Linear Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#logistic-regression" class="md-nav__link">
    <span class="md-ellipsis">
      Logistic Regression
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#decision-trees" class="md-nav__link">
    <span class="md-ellipsis">
      Decision Trees
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-forest" class="md-nav__link">
    <span class="md-ellipsis">
      Random Forest
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#gradient-boosting-xgboost-lightgbm" class="md-nav__link">
    <span class="md-ellipsis">
      Gradient Boosting (XGBoost, LightGBM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#support-vector-machines-svm" class="md-nav__link">
    <span class="md-ellipsis">
      Support Vector Machines (SVM)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-means-clustering" class="md-nav__link">
    <span class="md-ellipsis">
      K-Means Clustering
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-nearest-neighbors-knn" class="md-nav__link">
    <span class="md-ellipsis">
      K-Nearest Neighbors (KNN)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#neural-networks-deep-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Neural Networks (Deep Learning)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#naive-bayes" class="md-nav__link">
    <span class="md-ellipsis">
      Naive Bayes
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#random-cut-forest-rcf" class="md-nav__link">
    <span class="md-ellipsis">
      Random Cut Forest (RCF)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#principal-component-analysis-pca" class="md-nav__link">
    <span class="md-ellipsis">
      Principal Component Analysis (PCA)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-model-validation-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      3. Model Validation Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="3. Model Validation Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#train-test-split" class="md-nav__link">
    <span class="md-ellipsis">
      Train-Test Split
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      Cross-Validation
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#k-fold-cross-validation" class="md-nav__link">
    <span class="md-ellipsis">
      K-Fold Cross-Validation
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-evaluation-metrics" class="md-nav__link">
    <span class="md-ellipsis">
      4. Evaluation Metrics
    </span>
  </a>
  
    <nav class="md-nav" aria-label="4. Evaluation Metrics">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#confusion-matrix" class="md-nav__link">
    <span class="md-ellipsis">
      Confusion Matrix
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#accuracy" class="md-nav__link">
    <span class="md-ellipsis">
      Accuracy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#precision" class="md-nav__link">
    <span class="md-ellipsis">
      Precision
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#recall-sensitivity" class="md-nav__link">
    <span class="md-ellipsis">
      Recall (Sensitivity)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#f1-score" class="md-nav__link">
    <span class="md-ellipsis">
      F1 Score
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#roc-curve-receiver-operating-characteristic" class="md-nav__link">
    <span class="md-ellipsis">
      ROC Curve (Receiver Operating Characteristic)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auc-area-under-the-roc-curve" class="md-nav__link">
    <span class="md-ellipsis">
      AUC (Area Under the ROC Curve)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#auc-pr-area-under-the-precision-recall-curve" class="md-nav__link">
    <span class="md-ellipsis">
      AUC-PR (Area Under the Precision-Recall Curve)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-loss-functions" class="md-nav__link">
    <span class="md-ellipsis">
      5. Loss Functions
    </span>
  </a>
  
    <nav class="md-nav" aria-label="5. Loss Functions">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#mean-squared-error-mse" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Squared Error (MSE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mean-absolute-error-mae" class="md-nav__link">
    <span class="md-ellipsis">
      Mean Absolute Error (MAE)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#huber-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Huber Loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#binary-cross-entropy-log-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Binary Cross-Entropy (Log Loss)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#categorical-cross-entropy" class="md-nav__link">
    <span class="md-ellipsis">
      Categorical Cross-Entropy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#sparse-categorical-cross-entropy" class="md-nav__link">
    <span class="md-ellipsis">
      Sparse Categorical Cross-Entropy
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#hinge-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Hinge Loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#focal-loss" class="md-nav__link">
    <span class="md-ellipsis">
      Focal Loss
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#kullback-leibler-kl-divergence" class="md-nav__link">
    <span class="md-ellipsis">
      Kullback-Leibler (KL) Divergence
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-optimization-algorithms" class="md-nav__link">
    <span class="md-ellipsis">
      6. Optimization Algorithms
    </span>
  </a>
  
    <nav class="md-nav" aria-label="6. Optimization Algorithms">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#sgd-stochastic-gradient-descent" class="md-nav__link">
    <span class="md-ellipsis">
      SGD (Stochastic Gradient Descent)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#momentum" class="md-nav__link">
    <span class="md-ellipsis">
      Momentum
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#adam-adaptive-moment-estimation" class="md-nav__link">
    <span class="md-ellipsis">
      Adam (Adaptive Moment Estimation)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#rmsprop-root-mean-square-propagation" class="md-nav__link">
    <span class="md-ellipsis">
      RMSprop (Root Mean Square Propagation)
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-training-hyperparameters" class="md-nav__link">
    <span class="md-ellipsis">
      7. Training Hyperparameters
    </span>
  </a>
  
    <nav class="md-nav" aria-label="7. Training Hyperparameters">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#batch-size" class="md-nav__link">
    <span class="md-ellipsis">
      Batch Size
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#mini-batch" class="md-nav__link">
    <span class="md-ellipsis">
      Mini-batch
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#learning-rate" class="md-nav__link">
    <span class="md-ellipsis">
      Learning Rate
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-model-performance-issues" class="md-nav__link">
    <span class="md-ellipsis">
      8. Model Performance Issues
    </span>
  </a>
  
    <nav class="md-nav" aria-label="8. Model Performance Issues">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#bias-variance-tradeoff" class="md-nav__link">
    <span class="md-ellipsis">
      Bias-Variance Tradeoff
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#overfitting" class="md-nav__link">
    <span class="md-ellipsis">
      Overfitting
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#underfitting" class="md-nav__link">
    <span class="md-ellipsis">
      Underfitting
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-regularization-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      9. Regularization Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="9. Regularization Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#l1-regularization-lasso" class="md-nav__link">
    <span class="md-ellipsis">
      L1 Regularization (Lasso)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#l2-regularization-ridge" class="md-nav__link">
    <span class="md-ellipsis">
      L2 Regularization (Ridge)
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#dropout" class="md-nav__link">
    <span class="md-ellipsis">
      Dropout
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#early-stopping" class="md-nav__link">
    <span class="md-ellipsis">
      Early Stopping
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-advanced-ml-techniques" class="md-nav__link">
    <span class="md-ellipsis">
      10. Advanced ML Techniques
    </span>
  </a>
  
    <nav class="md-nav" aria-label="10. Advanced ML Techniques">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#transfer-learning" class="md-nav__link">
    <span class="md-ellipsis">
      Transfer Learning
    </span>
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#collaborative-filtering" class="md-nav__link">
    <span class="md-ellipsis">
      Collaborative Filtering
    </span>
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  



<h1 id="machine-learning-concepts---quick-reference">Machine Learning Concepts - Quick Reference<a class="headerlink" href="#machine-learning-concepts---quick-reference" title="Permanent link">&para;</a></h1>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>This page provides concise explanations of fundamental machine learning concepts for building, training, and evaluating models. Use this as a quick reference when implementing ML solutions, tuning hyperparameters, or diagnosing model performance issues.</p>
<p><strong>Related:</strong> See <a href="../ds_concepts/">Data Science Concepts</a> for data preparation, preprocessing, and transformation techniques that should be applied before model training.</p>
<hr />
<h2 id="1-core-ml-concepts">1. Core ML Concepts<a class="headerlink" href="#1-core-ml-concepts" title="Permanent link">&para;</a></h2>
<p><em>Fundamental principles underlying machine learning.</em></p>
<h3 id="supervised-learning">Supervised Learning<a class="headerlink" href="#supervised-learning" title="Permanent link">&para;</a></h3>
<p>Learning paradigm where model trains on labeled data (input-output pairs) to learn mapping from inputs to outputs. Includes classification (discrete outputs) and regression (continuous outputs). Requires labeled training data. Examples: predicting house prices, image classification, spam detection.</p>
<h3 id="unsupervised-learning">Unsupervised Learning<a class="headerlink" href="#unsupervised-learning" title="Permanent link">&para;</a></h3>
<p>Learning paradigm where model finds patterns in unlabeled data without explicit target variables. Includes clustering, dimensionality reduction, and anomaly detection. No right or wrong answers, discovers hidden structure. Examples: customer segmentation, topic modeling, compression.</p>
<h3 id="reinforcement-learning">Reinforcement Learning<a class="headerlink" href="#reinforcement-learning" title="Permanent link">&para;</a></h3>
<p>Learning paradigm where an agent learns to make decisions by taking actions in an environment to maximize cumulative reward. The agent learns through trial and error, receiving feedback as rewards or penalties. No labeled training data; instead learns optimal behavior through interaction. Applications include game playing, robotics, and autonomous systems.</p>
<hr />
<h2 id="2-ml-algorithm-types">2. ML Algorithm Types<a class="headerlink" href="#2-ml-algorithm-types" title="Permanent link">&para;</a></h2>
<p><em>Common machine learning algorithms categorized by problem type and approach.</em></p>
<h3 id="linear-regression">Linear Regression<a class="headerlink" href="#linear-regression" title="Permanent link">&para;</a></h3>
<p>Supervised learning algorithm for regression that models relationship between input features and continuous output using a linear equation: y = w₁x₁ + w₂x₂ + ... + b. Finds best-fit line/hyperplane by minimizing squared error. Simple, interpretable, fast to train. Assumes linear relationship between features and target. Used for price prediction, trend analysis, forecasting.</p>
<h3 id="logistic-regression">Logistic Regression<a class="headerlink" href="#logistic-regression" title="Permanent link">&para;</a></h3>
<p>Supervised learning algorithm for binary classification that predicts probability using sigmoid function: p = 1/(1 + e^(-z)). Despite name, used for classification not regression. Outputs probability between 0 and 1. Fast, interpretable, works well with linearly separable data. Used for spam detection, disease diagnosis, customer churn prediction.</p>
<h3 id="decision-trees">Decision Trees<a class="headerlink" href="#decision-trees" title="Permanent link">&para;</a></h3>
<p>Supervised learning algorithm that makes predictions by learning decision rules from features. Creates tree structure where each node represents a feature test, each branch represents an outcome, and each leaf represents a class label or value. Easy to interpret, handles non-linear relationships, no feature scaling needed. Prone to overfitting. Used for credit approval, medical diagnosis, customer segmentation.</p>
<h3 id="random-forest">Random Forest<a class="headerlink" href="#random-forest" title="Permanent link">&para;</a></h3>
<p>Ensemble learning algorithm that combines multiple decision trees trained on random subsets of data and features. Each tree votes, and majority vote (classification) or average (regression) determines final prediction. Reduces overfitting compared to single decision tree. Handles high-dimensional data well. Provides feature importance. Used for fraud detection, recommendation systems, feature selection.</p>
<h3 id="gradient-boosting-xgboost-lightgbm">Gradient Boosting (XGBoost, LightGBM)<a class="headerlink" href="#gradient-boosting-xgboost-lightgbm" title="Permanent link">&para;</a></h3>
<p>Ensemble learning algorithm that builds trees sequentially, where each tree corrects errors of previous trees. XGBoost and LightGBM are optimized implementations with regularization and efficient computation. Often achieves best performance on structured/tabular data. Requires careful tuning to avoid overfitting. Used for competitions, ranking problems, structured data prediction.</p>
<h3 id="support-vector-machines-svm">Support Vector Machines (SVM)<a class="headerlink" href="#support-vector-machines-svm" title="Permanent link">&para;</a></h3>
<p>Supervised learning algorithm that finds optimal hyperplane separating classes with maximum margin. Uses kernel trick to handle non-linear decision boundaries. Effective in high-dimensional spaces. Works well with clear margin of separation. Memory intensive for large datasets. Used for text classification, image recognition, bioinformatics.</p>
<h3 id="k-means-clustering">K-Means Clustering<a class="headerlink" href="#k-means-clustering" title="Permanent link">&para;</a></h3>
<p>Unsupervised learning algorithm that partitions data into K clusters by minimizing within-cluster variance. Iteratively assigns points to nearest centroid and updates centroids. Simple, fast, scalable. Requires specifying K in advance. Assumes spherical clusters. Used for customer segmentation, image compression, anomaly detection.</p>
<h3 id="k-nearest-neighbors-knn">K-Nearest Neighbors (KNN)<a class="headerlink" href="#k-nearest-neighbors-knn" title="Permanent link">&para;</a></h3>
<p>Supervised learning algorithm that classifies based on majority vote of K nearest neighbors or predicts based on their average. Non-parametric, no training phase (lazy learning). Simple to understand. Computationally expensive at prediction time. Sensitive to feature scaling and irrelevant features. Used for recommendation systems, pattern recognition, missing data imputation.</p>
<h3 id="neural-networks-deep-learning">Neural Networks (Deep Learning)<a class="headerlink" href="#neural-networks-deep-learning" title="Permanent link">&para;</a></h3>
<p>Supervised learning algorithms with multiple layers of interconnected neurons that learn hierarchical representations. Includes feedforward networks, CNNs (images), RNNs/LSTMs (sequences), Transformers (NLP). Can model complex non-linear relationships. Requires large amounts of data and computational resources. Used for computer vision, natural language processing, speech recognition, game playing.</p>
<h3 id="naive-bayes">Naive Bayes<a class="headerlink" href="#naive-bayes" title="Permanent link">&para;</a></h3>
<p>Supervised learning algorithm based on Bayes' theorem with "naive" assumption of feature independence. Fast to train and predict. Works well with high-dimensional data. Performs surprisingly well despite independence assumption. Used for text classification, spam filtering, sentiment analysis.</p>
<h3 id="random-cut-forest-rcf">Random Cut Forest (RCF)<a class="headerlink" href="#random-cut-forest-rcf" title="Permanent link">&para;</a></h3>
<p>Unsupervised learning algorithm for anomaly detection that builds ensemble of trees using random cuts through feature space. Assigns anomaly score based on how isolated a point is. Handles high-dimensional data efficiently. Doesn't require labeled anomalies. Used for fraud detection, system health monitoring, IoT sensor anomaly detection.</p>
<h3 id="principal-component-analysis-pca">Principal Component Analysis (PCA)<a class="headerlink" href="#principal-component-analysis-pca" title="Permanent link">&para;</a></h3>
<p>Unsupervised learning algorithm for dimensionality reduction that finds orthogonal axes (principal components) capturing maximum variance. Transforms features into uncorrelated components. Reduces feature space while preserving information. Helps with visualization and computational efficiency. Used for data compression, noise reduction, feature extraction.</p>
<hr />
<h2 id="3-model-validation-techniques">3. Model Validation Techniques<a class="headerlink" href="#3-model-validation-techniques" title="Permanent link">&para;</a></h2>
<p><em>Strategies to assess model performance and prevent overfitting.</em></p>
<h3 id="train-test-split">Train-Test Split<a class="headerlink" href="#train-test-split" title="Permanent link">&para;</a></h3>
<p>Divides dataset into separate training set (to fit model) and test set (to evaluate performance). Common splits: 70-30, 80-20, 90-10 depending on data size. Test set must never be used during training or hyperparameter tuning. Simple but can be unreliable with small datasets.</p>
<h3 id="cross-validation">Cross-Validation<a class="headerlink" href="#cross-validation" title="Permanent link">&para;</a></h3>
<p>Evaluates model by training on multiple different subsets of data and averaging results. Provides more reliable performance estimate than single train-test split. Uses all data for both training and validation, maximizing data efficiency. Essential for small datasets and hyperparameter tuning.</p>
<h3 id="k-fold-cross-validation">K-Fold Cross-Validation<a class="headerlink" href="#k-fold-cross-validation" title="Permanent link">&para;</a></h3>
<p>Divides data into k equal folds; trains k times, each time using k-1 folds for training and 1 for validation. Averages performance across all k runs for final estimate. Common k values: 5 or 10. Stratified k-fold maintains class proportions in each fold for classification.</p>
<hr />
<h2 id="4-evaluation-metrics">4. Evaluation Metrics<a class="headerlink" href="#4-evaluation-metrics" title="Permanent link">&para;</a></h2>
<p><em>Measures to assess model performance, especially for classification tasks.</em></p>
<h3 id="confusion-matrix">Confusion Matrix<a class="headerlink" href="#confusion-matrix" title="Permanent link">&para;</a></h3>
<p>A table showing counts of True Positives, True Negatives, False Positives, and False Negatives for classification models. Rows represent actual classes, columns represent predicted classes. Provides complete picture of classification performance beyond simple accuracy. Foundation for calculating precision, recall, F1, and other metrics.</p>
<h3 id="accuracy">Accuracy<a class="headerlink" href="#accuracy" title="Permanent link">&para;</a></h3>
<p>The proportion of correct predictions out of total predictions: (TP + TN) / (TP + TN + FP + FN). Simple metric but can be misleading with imbalanced datasets. A model predicting all negatives on 95% negative data achieves 95% accuracy but is useless. Best used when classes are balanced and errors are equally costly.</p>
<h3 id="precision">Precision<a class="headerlink" href="#precision" title="Permanent link">&para;</a></h3>
<p>The proportion of positive predictions that are actually correct: True Positives / (True Positives + False Positives). Answers "Of all items we labeled as positive, how many were truly positive?" High precision means low false positive rate. Important when false positives are costly (e.g., spam detection, medical diagnosis).</p>
<h3 id="recall-sensitivity">Recall (Sensitivity)<a class="headerlink" href="#recall-sensitivity" title="Permanent link">&para;</a></h3>
<p>The proportion of actual positives that were correctly identified: True Positives / (True Positives + False Negatives). Answers "Of all actual positive items, how many did we correctly identify?" High recall means low false negative rate. Important when missing positives is costly (e.g., cancer detection, fraud detection).</p>
<h3 id="f1-score">F1 Score<a class="headerlink" href="#f1-score" title="Permanent link">&para;</a></h3>
<p>Harmonic mean of precision and recall: 2 × (Precision × Recall) / (Precision + Recall). Balances precision and recall into a single metric, useful when both need to be reasonably high. Ranges from 0 to 1, with 1 being perfect. Preferred over accuracy for imbalanced datasets.</p>
<h3 id="roc-curve-receiver-operating-characteristic">ROC Curve (Receiver Operating Characteristic)<a class="headerlink" href="#roc-curve-receiver-operating-characteristic" title="Permanent link">&para;</a></h3>
<p>Graph plotting True Positive Rate (Recall) against False Positive Rate at various classification thresholds. Shows tradeoff between sensitivity and specificity across all possible thresholds. Curve closer to top-left corner indicates better performance. Useful for selecting optimal threshold for the use case.</p>
<h3 id="auc-area-under-the-roc-curve">AUC (Area Under the ROC Curve)<a class="headerlink" href="#auc-area-under-the-roc-curve" title="Permanent link">&para;</a></h3>
<p>Single number (0 to 1) summarizing ROC curve performance; measures probability that model ranks random positive higher than random negative. AUC of 0.5 means random guessing; 1.0 means perfect classification. Threshold-independent metric, useful for comparing models. Robust to class imbalance.</p>
<h3 id="auc-pr-area-under-the-precision-recall-curve">AUC-PR (Area Under the Precision-Recall Curve)<a class="headerlink" href="#auc-pr-area-under-the-precision-recall-curve" title="Permanent link">&para;</a></h3>
<p>Single number (0 to 1) summarizing the precision-recall curve; measures model performance across all classification thresholds by plotting precision against recall. Unlike AUC-ROC, AUC-PR focuses on the positive class performance and is more informative for highly imbalanced datasets where the minority class is of primary interest. Higher AUC-PR indicates better model performance on the positive class. Preferred over AUC-ROC when positive class is rare (fraud detection, rare disease diagnosis, anomaly detection).</p>
<hr />
<h2 id="5-loss-functions">5. Loss Functions<a class="headerlink" href="#5-loss-functions" title="Permanent link">&para;</a></h2>
<p><em>Metrics that quantify how wrong the model's predictions are.</em></p>
<h3 id="mean-squared-error-mse">Mean Squared Error (MSE)<a class="headerlink" href="#mean-squared-error-mse" title="Permanent link">&para;</a></h3>
<p>Measures average squared difference between predicted and actual values: (1/n) Σ(y - ŷ)². Most common loss function for regression problems. Heavily penalizes large errors due to squaring; sensitive to outliers. Differentiable everywhere, making it suitable for gradient-based optimization. Used in linear regression, neural networks for regression tasks. Units are squared (e.g., dollars² for price prediction).</p>
<h3 id="mean-absolute-error-mae">Mean Absolute Error (MAE)<a class="headerlink" href="#mean-absolute-error-mae" title="Permanent link">&para;</a></h3>
<p>Measures average absolute difference between predicted and actual values: (1/n) Σ|y - ŷ|. More robust to outliers than MSE since errors are not squared. Gives equal weight to all errors regardless of magnitude. Interpretable in original units (e.g., dollars for price prediction). Less sensitive to extreme values; suitable when outliers shouldn't dominate the loss.</p>
<h3 id="huber-loss">Huber Loss<a class="headerlink" href="#huber-loss" title="Permanent link">&para;</a></h3>
<p>Combines benefits of MSE and MAE; acts as MSE for small errors and MAE for large errors. Quadratic for errors below threshold δ, linear for errors above δ. More robust to outliers than MSE while maintaining differentiability. Common δ values: 1.0 or 1.35. Used in robust regression when dataset contains outliers but gradient-based optimization is needed.</p>
<h3 id="binary-cross-entropy-log-loss">Binary Cross-Entropy (Log Loss)<a class="headerlink" href="#binary-cross-entropy-log-loss" title="Permanent link">&para;</a></h3>
<p>Loss function for binary classification: -[y log(p) + (1-y) log(1-p)], where y is true label (0 or 1) and p is predicted probability. Heavily penalizes confident wrong predictions; small penalty for correct predictions with high confidence. Outputs range from 0 (perfect) to infinity (worst). Equivalent to negative log-likelihood for Bernoulli distribution. Standard loss for logistic regression and binary classification neural networks.</p>
<h3 id="categorical-cross-entropy">Categorical Cross-Entropy<a class="headerlink" href="#categorical-cross-entropy" title="Permanent link">&para;</a></h3>
<p>Extension of binary cross-entropy for multi-class classification: -Σ y_i log(p_i) across all classes. Compares one-hot encoded true labels with predicted probability distribution from softmax. Minimizing this loss is equivalent to maximizing log-likelihood. Used with softmax activation in neural networks for multi-class problems. Requires mutually exclusive classes (each sample belongs to exactly one class).</p>
<h3 id="sparse-categorical-cross-entropy">Sparse Categorical Cross-Entropy<a class="headerlink" href="#sparse-categorical-cross-entropy" title="Permanent link">&para;</a></h3>
<p>Functionally identical to categorical cross-entropy but accepts integer class labels instead of one-hot encoded vectors. Computationally more efficient for problems with many classes (hundreds or thousands). Example: class label is 5 instead of [0,0,0,0,0,1,0,...]. Commonly used in NLP tasks with large vocabularies and image classification with many categories.</p>
<h3 id="hinge-loss">Hinge Loss<a class="headerlink" href="#hinge-loss" title="Permanent link">&para;</a></h3>
<p>Loss function for maximum-margin classification, primarily used in SVMs: max(0, 1 - y·ŷ) where y ∈ {-1, 1} and ŷ is raw prediction. Encourages correct predictions to be beyond a margin; zero loss if prediction is correct and confident. Creates linear decision boundaries. Not probabilistic like cross-entropy; focuses on margin maximization. Used in SVMs and some neural network applications.</p>
<h3 id="focal-loss">Focal Loss<a class="headerlink" href="#focal-loss" title="Permanent link">&para;</a></h3>
<p>Modification of cross-entropy that down-weights easy examples and focuses on hard examples: -α(1-p)^γ log(p) for positive class. Parameter γ (typically 2) controls how much to focus on hard examples; α balances positive/negative classes. Addresses extreme class imbalance by reducing loss contribution from well-classified examples. Developed for object detection where easy negatives vastly outnumber hard positives. Particularly effective when 99%+ samples are easy negatives.</p>
<h3 id="kullback-leibler-kl-divergence">Kullback-Leibler (KL) Divergence<a class="headerlink" href="#kullback-leibler-kl-divergence" title="Permanent link">&para;</a></h3>
<p>Measures how one probability distribution differs from another: Σ P(x) log(P(x)/Q(x)). Asymmetric measure (KL(P||Q) ≠ KL(Q||P)); not a true distance metric. Used in variational autoencoders (VAEs) to match learned distribution to prior. Measures information loss when Q approximates P. Common in generative models and distribution matching tasks.</p>
<hr />
<h2 id="6-optimization-algorithms">6. Optimization Algorithms<a class="headerlink" href="#6-optimization-algorithms" title="Permanent link">&para;</a></h2>
<p><em>Methods for updating model weights during training.</em></p>
<h3 id="sgd-stochastic-gradient-descent">SGD (Stochastic Gradient Descent)<a class="headerlink" href="#sgd-stochastic-gradient-descent" title="Permanent link">&para;</a></h3>
<p>Updates weights using gradient computed from one random sample (or mini-batch) at a time. Faster per iteration than batch gradient descent and can escape local minima due to noise. Converges with fluctuations; learning rate scheduling often needed. Foundation for most modern optimizers.</p>
<h3 id="momentum">Momentum<a class="headerlink" href="#momentum" title="Permanent link">&para;</a></h3>
<p>Enhancement to SGD that adds fraction of previous update to current update, helping accelerate in consistent directions. Reduces oscillations and speeds up convergence by building velocity in gradient direction. Typical momentum parameter: 0.9. Think of it as a ball rolling downhill gaining speed.</p>
<h3 id="adam-adaptive-moment-estimation">Adam (Adaptive Moment Estimation)<a class="headerlink" href="#adam-adaptive-moment-estimation" title="Permanent link">&para;</a></h3>
<p>Combines momentum and adaptive learning rates; maintains per-parameter learning rates adapted based on gradient history. Computes adaptive learning rates from first (mean) and second (variance) moments of gradients. Widely used default optimizer; often works well with minimal tuning. Typical hyperparameters: β₁=0.9, β₂=0.999.</p>
<h3 id="rmsprop-root-mean-square-propagation">RMSprop (Root Mean Square Propagation)<a class="headerlink" href="#rmsprop-root-mean-square-propagation" title="Permanent link">&para;</a></h3>
<p>Adapts learning rate for each parameter based on recent gradient magnitudes using moving average of squared gradients. Divides learning rate by root of this average, preventing oscillations in steep directions. Effective for recurrent neural networks and non-stationary problems. Developed by Geoffrey Hinton.</p>
<hr />
<h2 id="7-training-hyperparameters">7. Training Hyperparameters<a class="headerlink" href="#7-training-hyperparameters" title="Permanent link">&para;</a></h2>
<p><em>Key parameters that control how models learn from data.</em></p>
<h3 id="batch-size">Batch Size<a class="headerlink" href="#batch-size" title="Permanent link">&para;</a></h3>
<p>The number of training examples used in one iteration to update model weights. Smaller batches (1-32) provide noisy but frequent updates; larger batches (128-512) provide stable but less frequent updates. Affects training speed, memory usage, and convergence quality. Common values: 32, 64, 128, 256.</p>
<h3 id="mini-batch">Mini-batch<a class="headerlink" href="#mini-batch" title="Permanent link">&para;</a></h3>
<p>A subset of the training data, larger than one example but smaller than the full dataset, used for gradient descent. Combines benefits of stochastic (fast, noisy updates) and batch (stable, accurate) gradient descent. Most common approach in modern deep learning. Typically ranges from 16 to 512 examples.</p>
<h3 id="learning-rate">Learning Rate<a class="headerlink" href="#learning-rate" title="Permanent link">&para;</a></h3>
<p>Controls the step size when updating model weights during training; determines how quickly the model adapts to the problem. Too high causes unstable training or divergence; too low causes slow convergence or getting stuck. Often the most important hyperparameter to tune. Typical starting values: 0.001 to 0.1.</p>
<hr />
<h2 id="8-model-performance-issues">8. Model Performance Issues<a class="headerlink" href="#8-model-performance-issues" title="Permanent link">&para;</a></h2>
<p><em>Understanding when the model learns too much, too little, or just right.</em></p>
<h3 id="bias-variance-tradeoff">Bias-Variance Tradeoff<a class="headerlink" href="#bias-variance-tradeoff" title="Permanent link">&para;</a></h3>
<p>Bias is error from wrong assumptions (underfitting); variance is error from sensitivity to training data fluctuations (overfitting). Models with high bias are too simple; high variance models are too complex. Optimal model minimizes total error = bias² + variance + irreducible error. Core challenge in model selection.</p>
<h3 id="overfitting">Overfitting<a class="headerlink" href="#overfitting" title="Permanent link">&para;</a></h3>
<p>When a model learns training data too well, including its noise and peculiarities, causing poor performance on new data. The model memorizes rather than generalizes. Signs include high training accuracy but low validation accuracy. Solution: Use regularization, more data, or simpler models.</p>
<h3 id="underfitting">Underfitting<a class="headerlink" href="#underfitting" title="Permanent link">&para;</a></h3>
<p>When a model is too simple to capture underlying patterns in the data, resulting in poor performance on both training and test data. The model lacks the capacity to learn the relationship between features and targets. Signs include low accuracy on both training and validation sets. Solution: Use more complex models, add features, or train longer.</p>
<hr />
<h2 id="9-regularization-techniques">9. Regularization Techniques<a class="headerlink" href="#9-regularization-techniques" title="Permanent link">&para;</a></h2>
<p><em>Methods to prevent overfitting by constraining model complexity.</em></p>
<h3 id="l1-regularization-lasso">L1 Regularization (Lasso)<a class="headerlink" href="#l1-regularization-lasso" title="Permanent link">&para;</a></h3>
<p>Adds penalty equal to absolute value of coefficient magnitudes to the loss function, encouraging sparsity by driving some weights to exactly zero. Useful for feature selection as it automatically eliminates less important features. The penalty term is λ∑|w|, where λ controls regularization strength. Creates sparse models that are easier to interpret.</p>
<h3 id="l2-regularization-ridge">L2 Regularization (Ridge)<a class="headerlink" href="#l2-regularization-ridge" title="Permanent link">&para;</a></h3>
<p>Adds penalty equal to square of coefficient magnitudes to the loss function, discouraging large weights but keeping all features. Distributes weights more evenly across features rather than eliminating them. The penalty term is λ∑w², where λ controls regularization strength. Preferred when all features are potentially relevant.</p>
<h3 id="dropout">Dropout<a class="headerlink" href="#dropout" title="Permanent link">&para;</a></h3>
<p>Randomly ignores (drops) a percentage of neurons during each training iteration in neural networks. Forces network to learn redundant representations, preventing over-reliance on specific neurons. Typical dropout rates: 0.2-0.5. Only applied during training, not inference.</p>
<h3 id="early-stopping">Early Stopping<a class="headerlink" href="#early-stopping" title="Permanent link">&para;</a></h3>
<p>Stops training when validation performance stops improving for specified number of epochs (patience). Prevents overfitting by avoiding unnecessary training iterations. Monitors validation loss and saves best model. Simple yet highly effective regularization technique.</p>
<hr />
<h2 id="10-advanced-ml-techniques">10. Advanced ML Techniques<a class="headerlink" href="#10-advanced-ml-techniques" title="Permanent link">&para;</a></h2>
<p><em>Specialized machine learning approaches for specific use cases.</em></p>
<h3 id="transfer-learning">Transfer Learning<a class="headerlink" href="#transfer-learning" title="Permanent link">&para;</a></h3>
<p>Technique that leverages knowledge from a pre-trained model (trained on large dataset) and adapts it to a new, related task with limited data. Instead of training from scratch, reuse learned features from the source task. Common approach: freeze early layers (general features like edges, textures) and fine-tune later layers (task-specific features). Dramatically reduces training time, data requirements, and computational costs.</p>
<p>When to Use:</p>
<ul>
<li>Limited labeled data for target task</li>
<li>Target task is similar to source task (e.g., both are image classification)</li>
<li>Want to leverage state-of-the-art pretrained models</li>
</ul>
<p>Common Approaches:</p>
<ul>
<li>Feature Extraction: Freeze all pretrained layers, only train new classifier on top</li>
<li>Fine-tuning: Unfreeze some layers and retrain them with small learning rate</li>
<li>Progressive Unfreezing: Gradually unfreeze layers from top to bottom during training</li>
</ul>
<p>Popular Pretrained Models:</p>
<ul>
<li>Vision: ResNet, VGG, EfficientNet, Vision Transformer (ViT)</li>
<li>NLP: BERT, GPT, T5, RoBERTa</li>
<li>Multi-modal: CLIP, Flamingo</li>
</ul>
<p>Example Workflow:</p>
<ol>
<li>Start with model pretrained on ImageNet (1.4M images, 1000 classes)</li>
<li>Remove final classification layer</li>
<li>Add new layer for specific classes (e.g., 10 classes)</li>
<li>Freeze pretrained layers, train only new layer</li>
<li>Optionally fine-tune top layers with low learning rate</li>
</ol>
<p>Benefits:</p>
<ul>
<li>Requires 10-100x less data than training from scratch</li>
<li>Converges faster (hours vs days/weeks)</li>
<li>Often achieves better performance, especially with limited data</li>
<li>Reduces computational costs significantly</li>
</ul>
<p>GCP Implementation:
Vertex AI AutoML uses transfer learning automatically with Google's pretrained models. For custom training, TensorFlow Hub and Hugging Face provide pretrained models.</p>
<h3 id="collaborative-filtering">Collaborative Filtering<a class="headerlink" href="#collaborative-filtering" title="Permanent link">&para;</a></h3>
<p>Recommendation technique that makes predictions based on preferences of similar users or items. User-based finds users with similar tastes; item-based finds similar items. Doesn't require explicit feature engineering, works from interaction patterns (ratings, purchases, clicks). Used by Netflix, Amazon, and Spotify for recommendations.</p>












                
              </article>
            </div>
          
          
  <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script>

<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg>
  Back to top
</button>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "..", "features": ["navigation.sections", "navigation.top", "navigation.instant", "content.code.copy", "content.tabs.link", "toc.follow"], "search": "../assets/javascripts/workers/search.973d3a69.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../assets/javascripts/bundle.f55a23d4.min.js"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  </body>
</html>